{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle5 as pickle\n",
    "from PIL import Image\n",
    "import json\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open(f\"../../datasets/data_230710/annotations/train/anno.pkl\", \"rb\") as st_json:\n",
    "    meta = pickle.load(st_json)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def get_transform(center, scale, res, rot=0):\n",
    "    \"\"\"Generate transformation matrix.\"\"\"\n",
    "    h = res[0] * scale\n",
    "    # h = 200 * scale\n",
    "    t = np.zeros((3, 3))\n",
    "    t[0, 0] = float(res[1]) / h\n",
    "    t[1, 1] = float(res[0]) / h\n",
    "    t[0, 2] = res[1] * (-float(center[0]) / h + .5)\n",
    "    t[1, 2] = res[0] * (-float(center[1]) / h + .5)\n",
    "    t[2, 2] = 1\n",
    "    if not rot == 0:\n",
    "        rot = -rot # To match direction of rotation from cropping\n",
    "        rot_mat = np.zeros((3,3))\n",
    "        rot_rad = rot * np.pi / 180\n",
    "        sn,cs = np.sin(rot_rad), np.cos(rot_rad)\n",
    "        rot_mat[0,:2] = [cs, -sn]\n",
    "        rot_mat[1,:2] = [sn, cs]\n",
    "        rot_mat[2,2] = 1\n",
    "        # Need to rotate around center\n",
    "        t_mat = np.eye(3)\n",
    "        t_mat[0,2] = -res[1]/2\n",
    "        t_mat[1,2] = -res[0]/2\n",
    "        t_inv = t_mat.copy()\n",
    "        t_inv[:2,2] *= -1\n",
    "        t = np.dot(t_inv,np.dot(rot_mat,np.dot(t_mat,t)))\n",
    "    return t\n",
    "\n",
    "\n",
    "def transform(pt, center, scale, res, invert=0, rot=0):\n",
    "    \"\"\"Transform pixel location to different reference.\"\"\"\n",
    "    t = get_transform(center, scale, res, rot=rot)\n",
    "    if invert:\n",
    "        # t = np.linalg.inv(t)\n",
    "        t_torch = torch.from_numpy(t)\n",
    "        t_torch = torch.inverse(t_torch)\n",
    "        t = t_torch.numpy()\n",
    "    new_pt = np.array([pt[0]-1, pt[1]-1, 1.]).T\n",
    "    new_pt = np.dot(t, new_pt)\n",
    "    return new_pt[:2].astype(int)+1\n",
    "\n",
    "\n",
    "def crop(img, center, scale, res, rot=0):\n",
    "    \"\"\"Crop image according to the supplied bounding box.\"\"\"\n",
    "    # Upper left point\n",
    "    ul = np.array(transform([1, 1], center, scale, res, invert=1))-1\n",
    "    # Bottom right point\n",
    "    br = np.array(transform([res[0]+1, \n",
    "                             res[1]+1], center, scale, res, invert=1))-1\n",
    "    # Padding so that when rotated proper amount of context is included\n",
    "    pad = int(np.linalg.norm(br - ul) / 2 - float(br[1] - ul[1]) / 2)\n",
    "    if not rot == 0:\n",
    "        ul -= pad\n",
    "        br += pad\n",
    "    new_shape = [br[1] - ul[1], br[0] - ul[0]]\n",
    "    if len(img.shape) > 2:\n",
    "        new_shape += [img.shape[2]]\n",
    "    new_img = np.zeros(new_shape)\n",
    "\n",
    "    # Range to fill new array\n",
    "    new_x = max(0, -ul[0]), min(br[0], len(img[0])) - ul[0]\n",
    "    new_y = max(0, -ul[1]), min(br[1], len(img)) - ul[1]\n",
    "    # Range to sample from original image\n",
    "    old_x = max(0, ul[0]), min(len(img[0]), br[0])\n",
    "    old_y = max(0, ul[1]), min(len(img), br[1])\n",
    "\n",
    "    new_img[new_y[0]:new_y[1], new_x[0]:new_x[1]] = img[old_y[0]:old_y[1], \n",
    "                                                        old_x[0]:old_x[1]]\n",
    "    if not rot == 0:\n",
    "        # Remove padding\n",
    "        # new_img = scipy.misc.imrotate(new_img, rot)\n",
    "        new_img = myimrotate(new_img, rot)\n",
    "        new_img = new_img[pad:-pad, pad:-pad]\n",
    "\n",
    "    # new_img = scipy.misc.imresize(new_img, res)\n",
    "    new_img = myimresize(new_img, [res[0], res[1]])\n",
    "    return new_img\n",
    "\n",
    "\n",
    "def myimrotate(img, angle, center=None, scale=1.0, border_value=0, auto_bound=False):\n",
    "    if center is not None and auto_bound:\n",
    "        raise ValueError('`auto_bound` conflicts with `center`')\n",
    "    h, w = img.shape[:2]\n",
    "    if center is None:\n",
    "        center = ((w - 1) * 0.5, (h - 1) * 0.5)\n",
    "    assert isinstance(center, tuple)\n",
    "\n",
    "    matrix = cv2.getRotationMatrix2D(center, angle, scale)\n",
    "    if auto_bound:\n",
    "        cos = np.abs(matrix[0, 0])\n",
    "        sin = np.abs(matrix[0, 1])\n",
    "        new_w = h * sin + w * cos\n",
    "        new_h = h * cos + w * sin\n",
    "        matrix[0, 2] += (new_w - w) * 0.5\n",
    "        matrix[1, 2] += (new_h - h) * 0.5\n",
    "        w = int(np.round(new_w))\n",
    "        h = int(np.round(new_h))\n",
    "    rotated = cv2.warpAffine(img, matrix, (w, h), borderValue=border_value)\n",
    "    return rotated\n",
    "\n",
    "def myimresize(img, size, return_scale=False):\n",
    "\n",
    "    h, w = img.shape[:2]\n",
    "    resized_img = cv2.resize(\n",
    "        img, (size[0],size[1]))\n",
    "    if not return_scale:\n",
    "        return resized_img\n",
    "    else:\n",
    "        w_scale = size[0] / w\n",
    "        h_scale = size[1] / h\n",
    "        return resized_img, w_scale, h_scale\n",
    "    \n",
    "\n",
    "def j2d_processing(kp, scale, r):\n",
    "    \"\"\"Process gt 2D keypoints and apply all augmentation transforms.\"\"\"\n",
    "    nparts = kp.shape[0]\n",
    "    for i in range(nparts):\n",
    "        kp[i, 0:2] = transform(kp[i, 0:2]+1, (512/2, 512/2), scale,\n",
    "                                [512, 512], rot=r)\n",
    "    return kp\n",
    "\n",
    "def transform(pt, center, scale, res, invert=0, rot=0):\n",
    "    \"\"\"Transform pixel location to different reference.\"\"\"\n",
    "    t = get_transform(center, scale, res, rot=rot)\n",
    "    if invert:\n",
    "        # t = np.linalg.inv(t)\n",
    "        t_torch = torch.from_numpy(t)\n",
    "        t_torch = torch.inverse(t_torch)\n",
    "        t = t_torch.numpy()\n",
    "    new_pt = np.array([pt[0]-1, pt[1]-1, 1.]).T\n",
    "    new_pt = np.dot(t, new_pt)\n",
    "    return new_pt[:2].astype(int)+1\n",
    "\n",
    "colors = np.array([[0.4, 0.4, 0.4],\n",
    "                [0.4, 0.0, 0.0],\n",
    "                [0.6, 0.0, 0.0],\n",
    "                [0.8, 0.0, 0.0],\n",
    "                [1.0, 0.0, 0.0],\n",
    "                [0.4, 0.4, 0.0],\n",
    "                [0.6, 0.6, 0.0],\n",
    "                [0.8, 0.8, 0.0],\n",
    "                [1.0, 1.0, 0.0],\n",
    "                [0.0, 0.4, 0.2],\n",
    "                [0.0, 0.6, 0.3],\n",
    "                [0.0, 0.8, 0.4],\n",
    "                [0.0, 1.0, 0.5],\n",
    "                [0.0, 0.2, 0.4],\n",
    "                [0.0, 0.3, 0.6],\n",
    "                [0.0, 0.4, 0.8],\n",
    "                [0.0, 0.5, 1.0],\n",
    "                [0.4, 0.0, 0.4],\n",
    "                [0.6, 0.0, 0.6],\n",
    "                [0.7, 0.0, 0.8],\n",
    "                [1.0, 0.0, 1.0]])\n",
    "\n",
    "colors = colors[:, ::-1]\n",
    "\n",
    "# define connections and colors of the bones\n",
    "bones = [((0, 1), colors[1, :]),\n",
    "        ((1, 2), colors[2, :]),\n",
    "        ((2, 3), colors[3, :]),\n",
    "        ((3, 4), colors[4, :]),\n",
    "\n",
    "        ((0, 5), colors[5, :]),\n",
    "        ((5, 6), colors[6, :]),\n",
    "        ((6, 7), colors[7, :]),\n",
    "        ((7, 8), colors[8, :]),\n",
    "\n",
    "        ((0, 9), colors[9, :]),\n",
    "        ((9, 10), colors[10, :]),\n",
    "        ((10, 11), colors[11, :]),\n",
    "        ((11, 12), colors[12, :]),\n",
    "\n",
    "        ((0, 13), colors[13, :]),\n",
    "        ((13, 14), colors[14, :]),\n",
    "        ((14, 15), colors[15, :]),\n",
    "        ((15, 16), colors[16, :]),\n",
    "\n",
    "        ((0, 17), colors[17, :]),\n",
    "        ((17, 18), colors[18, :]),\n",
    "        ((18, 19), colors[19, :]),\n",
    "        ((19, 20), colors[20, :])]\n",
    "    \n",
    "def visualize(image, joint_2d):\n",
    "    parents = np.array([-1, 0, 1, 2, 3, 0, 5, 6, 7, 0, 9, 10, 11, 0, 13, 14, 15, 0, 17, 18, 19])\n",
    "    for i in range(21):\n",
    "        cv2.circle(image, (int(joint_2d[i][0]), int(joint_2d[i][1])), 2, colors[i] * 255,\n",
    "                    thickness=2)\n",
    "        if i != 0:\n",
    "            cv2.line(image, (int(joint_2d[i][0]), int(joint_2d[i][1])),\n",
    "                        (int(joint_2d[parents[i]][0]), int(joint_2d[parents[i]][1])),\n",
    "                        colors[i] * 255, 2)\n",
    "            \n",
    "    return image\n",
    "\n",
    "\n",
    "for idx in range(600, 650):\n",
    "\n",
    "    raw_res = 800\n",
    "    bg_path = \"../../datasets/data_230710/background\"\n",
    "    bg_list = os.listdir(bg_path)\n",
    "    img_path = os.path.join(\"../../datasets/data_230710\", f\"images/train\")\n",
    "    name = '/'.join(meta[idx]['file_name'].split('/')[1:])\n",
    "    image = cv2.imread(os.path.join(img_path, name))  # PIL image\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)[:,:, (2, 1, 0)]\n",
    "    \n",
    "    joint_2d = np.array(meta[idx]['joint_2d'])\n",
    "    joint_3d = meta[idx]['camera_coor_3d']    \n",
    "    scale = meta[idx]['scale']   \n",
    "    rot = meta[idx]['rot']       \n",
    "\n",
    "    cropped_img = crop(image, (raw_res/2, raw_res/2), scale, [raw_res, raw_res], rot=rot)\n",
    "    bg_img = cv2.imread(os.path.join(bg_path, bg_list[idx%len(bg_list)]))\n",
    "    bg_img = cv2.cvtColor(bg_img, cv2.COLOR_BGR2RGB)\n",
    "    bg_img = cv2.resize(bg_img[:, :, (2, 1, 0)], (raw_res, raw_res))\n",
    "    \n",
    "    # plt.imshow(image[:, :, (2,1,0)]/ 255)\n",
    "    # plt.show()\n",
    "\n",
    "    # plt.imshow(cropped_img[:, :, (2,1,0)]/255)\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "    cv2.imwrite(f'sample_img/{idx}_st_ori.jpg', image)\n",
    "    cv2.imwrite(f'sample_img/{idx}_st_cropped.jpg', cropped_img)\n",
    "\n",
    "    iaz = np.where((cropped_img[:, :, 0] == 0) & (cropped_img[:, :, 1] == 0) & (cropped_img[:, :, 2] == 0))\n",
    "    cropped_img[iaz] = bg_img[iaz]\n",
    "\n",
    "    # plt.imshow(bg_img/ 255)\n",
    "    # plt.show()\n",
    "\n",
    "    cv2.imwrite(f'sample_img/{idx}_st_bg.jpg', bg_img)\n",
    "\n",
    "    cv2.imwrite(f'sample_img/{idx}_st_output.jpg', cropped_img)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('dart')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "07213e03326ce730c48dae615f5c2176c2ed3cdd905958a5ad19a9446ed04698"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
